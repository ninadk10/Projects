{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea107c31",
   "metadata": {},
   "source": [
    "#### This notebook is heavily based off: https://github.com/Azure/azureml-examples/blob/main/v1/python-sdk/tutorials/automl-with-azureml/forecasting-hierarchical-timeseries/auto-ml-forecasting-hierarchical-timeseries.ipynb\n",
    "#### Use the two in conjunction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bce061d",
   "metadata": {},
   "source": [
    "#### Install required packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07930168",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install azureml-train-automl --user\n",
    "pip install azure-ai-ml azureml-core azure-identity azureml-mlflow mlflow\n",
    "pip install azureml-dataset-runtime --upgrade\n",
    "pip install azureml-contrib-automl-pipeline-steps\n",
    "pip install pyOpenSSL\n",
    "pip install cryptography==38.0.4 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "191bc21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.identity import AzureCliCredential\n",
    "from azure.ai.ml import automl, Input, MLClient, command\n",
    "\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml.entities import Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710f807e",
   "metadata": {},
   "source": [
    "#### Authenticate via AzureCLI separately and then connect to workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8dbf1f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SDK version</th>\n",
       "      <td>1.49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subscription ID</th>\n",
       "      <td>d9412b06-e31c-4c66-b2c5-5e77beb91bc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Workspace</th>\n",
       "      <td>demo-ws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource Group</th>\n",
       "      <td>demo-rg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>uksouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Default datastore name</th>\n",
       "      <td>workspaceblobstore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SDK Version</th>\n",
       "      <td>1.49.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            \n",
       "SDK version                                           1.49.0\n",
       "Subscription ID         d9412b06-e31c-4c66-b2c5-5e77beb91bc1\n",
       "Workspace                                            demo-ws\n",
       "Resource Group                                       demo-rg\n",
       "Location                                             uksouth\n",
       "Default datastore name                    workspaceblobstore\n",
       "SDK Version                                           1.49.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Datastore\n",
    "import pandas as pd\n",
    "\n",
    "# Set up your workspace\n",
    "ws = Workspace.from_config()\n",
    "ws.get_details()\n",
    "\n",
    "# Set up your datastores\n",
    "dstore = ws.get_default_datastore()\n",
    "\n",
    "output = {}\n",
    "output[\"SDK version\"] = azureml.core.VERSION\n",
    "output[\"Subscription ID\"] = ws.subscription_id\n",
    "output[\"Workspace\"] = ws.name\n",
    "output[\"Resource Group\"] = ws.resource_group\n",
    "output[\"Location\"] = ws.location\n",
    "output[\"Default datastore name\"] = dstore.name\n",
    "output[\"SDK Version\"] = azureml.core.VERSION\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "outputDf = pd.DataFrame(data=output, index=[\"\"])\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7edfe66",
   "metadata": {},
   "source": [
    "#### Create experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d015ffeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment name: automl-hts\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment = Experiment(ws, \"automl-hts\")\n",
    "\n",
    "print(\"Experiment name: \" + experiment.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94cb0d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_path = \"hts-sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f8a095a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"name\": \"workspaceblobstore\",\n",
       "  \"container_name\": \"azureml-blobstore-8343b37d-a835-4e2d-8040-a061b9b90fba\",\n",
       "  \"account_name\": \"demows8714441228\",\n",
       "  \"protocol\": \"https\",\n",
       "  \"endpoint\": \"core.windows.net\"\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datastore = ws.get_default_datastore()\n",
    "datastore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19639d61",
   "metadata": {},
   "source": [
    "#### Set up data for train and test, MLTables are created from the csvs below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb3aeb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Successfully obtained datastore reference and path.\n",
      "Uploading file to hts-sample/221ef6a1-4d9c-43e3-8140-a50ac15ae85c/\n",
      "Successfully uploaded file to datastore.\n",
      "Creating and registering a new dataset.\n",
      "Successfully created and registered a new dataset.\n",
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Successfully obtained datastore reference and path.\n",
      "Uploading file to hts-sample/0cf1ef30-6a50-4448-b7f8-a304809a0ebd/\n",
      "Successfully uploaded file to datastore.\n",
      "Creating and registering a new dataset.\n",
      "Successfully created and registered a new dataset.\n"
     ]
    }
   ],
   "source": [
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "\n",
    "registered_train = TabularDatasetFactory.register_pandas_dataframe(\n",
    "    pd.read_csv(\"Data/hts-sample-train.csv\"),\n",
    "    target=(datastore, \"hts-sample\"),\n",
    "    name=\"hts-sales-train\",\n",
    ")\n",
    "registered_inference = TabularDatasetFactory.register_pandas_dataframe(\n",
    "    pd.read_csv(\"Data/hts-sample-test.csv\"),\n",
    "    target=(datastore, \"hts-sample\"),\n",
    "    name=\"hts-sales-test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e78e5d",
   "metadata": {},
   "source": [
    "#### Find or create/configure compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0b4079b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found compute target: hts-compute\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "\n",
    "# Name your cluster\n",
    "compute_name = \"hts-compute\"\n",
    "\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print(\"Found compute target: \" + compute_name)\n",
    "else:\n",
    "    print(\"Creating a new compute target...\")\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=\"STANDARD_DS12_V2\", max_nodes=6\n",
    "    )\n",
    "    # Create the compute target\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "\n",
    "    # Can poll for a minimum number of nodes and for a specific timeout.\n",
    "    # If no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(\n",
    "        show_output=True, min_node_count=None, timeout_in_minutes=2\n",
    "    )\n",
    "\n",
    "    # For a more detailed view of current cluster status, use the 'status' property\n",
    "    print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebca6502",
   "metadata": {},
   "source": [
    "#### Configure Forecasting parameters, AutoML settings and HTS parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ec4001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl.runtime._hts.hts_parameters import HTSTrainParameters\n",
    "from azureml.automl.core.forecasting_parameters import ForecastingParameters\n",
    "from azureml.train.automl.automlconfig import AutoMLConfig\n",
    "\n",
    "\n",
    "model_explainability = True\n",
    "\n",
    "engineered_explanations = False\n",
    "# Define your hierarchy. Adjust the settings below based on your dataset.\n",
    "hierarchy = [\"state\", \"store_id\", \"product_category\", \"SKU\"]\n",
    "training_level = \"SKU\"\n",
    "\n",
    "# Set your forecast parameters. Adjust the settings below based on your dataset.\n",
    "time_column_name = \"date\"\n",
    "label_column_name = \"quantity\"\n",
    "forecast_horizon = 7\n",
    "\n",
    "forecasting_parameters = ForecastingParameters(\n",
    "    time_column_name=time_column_name,\n",
    "    forecast_horizon=forecast_horizon,\n",
    ")\n",
    "\n",
    "automl_settings = AutoMLConfig(\n",
    "    task=\"forecasting\",\n",
    "    primary_metric=\"normalized_root_mean_squared_error\",\n",
    "    experiment_timeout_hours=1,\n",
    "    label_column_name=label_column_name,\n",
    "    track_child_runs=False,\n",
    "    forecasting_parameters=forecasting_parameters,\n",
    "    pipeline_fetch_max_batch_size=15,\n",
    "    model_explainability=model_explainability,\n",
    "    n_cross_validations=\"auto\",  # Feel free to set to a small integer (>=2) if runtime is an issue.\n",
    "    cv_step_size=\"auto\",\n",
    "    # The following settings are specific to this sample and should be adjusted according to your own needs.\n",
    "    iteration_timeout_minutes=10,\n",
    "    iterations=15,\n",
    ")\n",
    "\n",
    "hts_parameters = HTSTrainParameters(\n",
    "    automl_settings=automl_settings,\n",
    "    hierarchy_column_names=hierarchy,\n",
    "    training_level=training_level,\n",
    "    enable_engineered_explanations=engineered_explanations,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062261d8",
   "metadata": {},
   "source": [
    "#### Configure training pipeline steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afd5c636",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Forecasting parameter country_or_region will be deprecated in the future, please use country_or_region_for_holidays instead.\n",
      "WARNING:root:Forecasting parameter grain_column_names will be deprecated in the future, please use time_series_id_column_names instead.\n",
      "WARNING:root:Forecasting parameter max_horizon will be deprecated in the future, please use forecast_horizon instead.\n",
      "WARNING:root:Parameter `preprocess` will be deprecated. Use `featurization`\n",
      "WARNING:root:Detected both `preprocess` and `featurization`. `preprocess` is being deprecated and will be overridden by `featurization` setting.\n",
      "WARNING:root:Parameter 'auto_blacklist' will be deprecated and enabled by default moving forward.'\n",
      "WARNING:root:Get_data scripts will be deprecated. Instead of parameter 'data_script', please pass a Dataset object into using the 'training_data' parameter.\n",
      "WARNING:root:Parameter 'drop_column_names' will be deprecated. Please drop columns from your datasets as part of your data preparation process before providing the datasets to AutoML.\n",
      "WARNING:root:cost_mode is an internal parameter that should not be used for regular experiments.\n",
      "WARNING:root:save_mlflow is an internal parameter that should not be used for regular experiments.\n",
      "WARNING:root:start_auxiliary_runs_before_parent_complete is an internal parameter that should not be used for regular experiments.\n",
      "WARNING:azureml._base_sdk_common._docstring_wrapper:Class LinkTabularOutputDatasetConfig: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A partitioned tabular dataset will be created with the name training after hts_raw_partitioned_1677581889. You may use it for future training.\n",
      "Aggregation dataset is created with the name hts_agg_1677581889\n"
     ]
    }
   ],
   "source": [
    "from azureml.contrib.automl.pipeline.steps import AutoMLPipelineBuilder\n",
    "\n",
    "\n",
    "training_pipeline_steps = AutoMLPipelineBuilder.get_many_models_train_steps(\n",
    "    experiment=experiment,\n",
    "    train_data=registered_train,\n",
    "    compute_target=compute_target,\n",
    "    node_count=1,\n",
    "    process_count_per_node=8,\n",
    "    train_pipeline_parameters=hts_parameters,\n",
    "    run_invocation_timeout=3900,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5d5d170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "training_pipeline = Pipeline(ws, steps=training_pipeline_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "930cdf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step hts-training-dataset-partition [301bfc38][01d2c796-bebb-41f0-b61c-f6ece57c735b], (This step will run and generate new outputs)\n",
      "Created step hts-hierarchy-builder [d8dd7a66][dc328a63-75b6-4f5b-9e3b-680e70781c46], (This step will run and generate new outputs)\n",
      "Created step hts-data-aggregation [5bb3f585][ac445ab4-9942-4492-90b9-cbbffbe6ead2], (This step will run and generate new outputs)\n",
      "Created step hts-automl-training [49a77619][7a908da2-c3ea-48c0-861a-fc57bc6d97a5], (This step will run and generate new outputs)\n",
      "Created step hts-proportions-calculation [7f015aed][d4e65533-027e-4cc1-b8dd-6f9f0b3ad536], (This step will run and generate new outputs)\n",
      "Created step hts-explanation-allocation [09a19425][a0479697-9620-46f5-939e-95f775cebd09], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun e2be9091-7f3b-435a-b1a8-a98071a09ec3\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/e2be9091-7f3b-435a-b1a8-a98071a09ec3?wsid=/subscriptions/d9412b06-e31c-4c66-b2c5-5e77beb91bc1/resourcegroups/demo-rg/workspaces/demo-ws&tid=dd1f2c2d-fea2-4bb0-a462-dfeb75d6a2e7\n"
     ]
    }
   ],
   "source": [
    "training_run = experiment.submit(training_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7e268bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: e2be9091-7f3b-435a-b1a8-a98071a09ec3\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/e2be9091-7f3b-435a-b1a8-a98071a09ec3?wsid=/subscriptions/d9412b06-e31c-4c66-b2c5-5e77beb91bc1/resourcegroups/demo-rg/workspaces/demo-ws&tid=dd1f2c2d-fea2-4bb0-a462-dfeb75d6a2e7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_run.wait_for_completion(show_output=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af45a9ee",
   "metadata": {},
   "source": [
    "#### Download model explanations locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "953af567",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_explainability:\n",
    "    expl_output = training_run.get_pipeline_output(\"explanations\")\n",
    "    expl_output.download(\"training_explanations\")\n",
    "else:\n",
    "    print(\n",
    "        \"Model explanations are available only if model_explainability is set to True.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61130e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The explanations are located at ec07a45e-83fb-462e-ad06-272949cdf215.\n",
      "Available explanations\n",
      "==============================\n",
      "raw_explanations_AUTOML_TOP_LEVEL.csv\n",
      "raw_explanations_product_category.csv\n",
      "raw_explanations_SKU.csv\n",
      "raw_explanations_state.csv\n",
      "raw_explanations_store_id.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if model_explainability:\n",
    "    explanations_dirrectory = os.listdir(\n",
    "        os.path.join(\"training_explanations\", \"azureml\")\n",
    "    )\n",
    "    if len(explanations_dirrectory) > 1:\n",
    "        print(\n",
    "            \"Warning! The directory contains multiple explanations, only the first one will be displayed.\"\n",
    "        )\n",
    "    print(\"The explanations are located at {}.\".format(explanations_dirrectory[0]))\n",
    "    # Now we will list all the explanations.\n",
    "    explanation_path = os.path.join(\n",
    "        \"training_explanations\",\n",
    "        \"azureml\",\n",
    "        explanations_dirrectory[0],\n",
    "        \"training_explanations\",\n",
    "    )\n",
    "    print(\"Available explanations\")\n",
    "    print(\"==============================\")\n",
    "    print(\"\\n\".join(os.listdir(explanation_path)))\n",
    "else:\n",
    "    print(\n",
    "        \"Model explanations are available only if model_explainability is set to True.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31b48f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA</td>\n",
       "      <td>2.88</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FL</td>\n",
       "      <td>4.88</td>\n",
       "      <td>4.37</td>\n",
       "      <td>49.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WA</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  date  price  quantity\n",
       "0    CA  2.88   1.28      0.05\n",
       "1    FL  4.88   4.37     49.47\n",
       "2    WA  2.80   2.05      1.34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "explanation_type = \"raw\"\n",
    "level = \"state\"\n",
    "\n",
    "if model_explainability:\n",
    "    display(\n",
    "        pd.read_csv(\n",
    "            os.path.join(explanation_path, \"{}_explanations_{}.csv\").format(\n",
    "                explanation_type, level\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7a16a3",
   "metadata": {},
   "source": [
    "#### Setup inference params and compute needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed39f8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training run used for inference is e2be9091-7f3b-435a-b1a8-a98071a09ec3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:azureml._base_sdk_common._docstring_wrapper:Class LinkTabularOutputDatasetConfig: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A partitioned tabular dataset will be created with the name inference after hts_raw_partitioned_1677588191. You may use it for future inference.\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.automl.runtime._hts.hts_parameters import HTSInferenceParameters\n",
    "\n",
    "inference_parameters = HTSInferenceParameters(\n",
    "    hierarchy_forecast_level=\"store_id\",  # The setting is specific to this dataset and should be changed based on your dataset.\n",
    "    allocation_method=\"proportions_of_historical_average\",\n",
    ")\n",
    "\n",
    "steps = AutoMLPipelineBuilder.get_many_models_batch_inference_steps(\n",
    "    experiment=experiment,\n",
    "    inference_data=registered_inference,\n",
    "    compute_target=compute_target,\n",
    "    inference_pipeline_parameters=inference_parameters,\n",
    "    node_count=1,\n",
    "    process_count_per_node=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ff6f9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "inference_pipeline = Pipeline(ws, steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcaba181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step hts-inference-dataset-partition [965b7a5c][366371b1-d192-4ec2-a65f-240ceea02472], (This step will run and generate new outputs)\n",
      "Created step hts-forecast-parallel [e1b25894][68806cc3-e75a-4b71-bd6d-43791a85026d], (This step will run and generate new outputs)\n",
      "Created step hts-forecast-allocation [10e9942c][4c21f674-4b55-477e-8e93-8830e6963709], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 120437da-5147-4254-aea0-4564dc5c7dcd\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/120437da-5147-4254-aea0-4564dc5c7dcd?wsid=/subscriptions/d9412b06-e31c-4c66-b2c5-5e77beb91bc1/resourcegroups/demo-rg/workspaces/demo-ws&tid=dd1f2c2d-fea2-4bb0-a462-dfeb75d6a2e7\n",
      "PipelineRunId: 120437da-5147-4254-aea0-4564dc5c7dcd\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/120437da-5147-4254-aea0-4564dc5c7dcd?wsid=/subscriptions/d9412b06-e31c-4c66-b2c5-5e77beb91bc1/resourcegroups/demo-rg/workspaces/demo-ws&tid=dd1f2c2d-fea2-4bb0-a462-dfeb75d6a2e7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_run = experiment.submit(inference_pipeline)\n",
    "inference_run.wait_for_completion(show_output=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1119f2d",
   "metadata": {},
   "source": [
    "#### download inference output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57b50cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts = inference_run.get_pipeline_output(\"forecasts\")\n",
    "forecasts.download(\"forecast_results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42d0a39",
   "metadata": {},
   "source": [
    "#### Try the run with different params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5ec87b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted PipelineRun 79ccc978-b32f-44b9-81ac-e26e950a902e\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/79ccc978-b32f-44b9-81ac-e26e950a902e?wsid=/subscriptions/d9412b06-e31c-4c66-b2c5-5e77beb91bc1/resourcegroups/demo-rg/workspaces/demo-ws&tid=dd1f2c2d-fea2-4bb0-a462-dfeb75d6a2e7\n",
      "PipelineRunId: 79ccc978-b32f-44b9-81ac-e26e950a902e\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/79ccc978-b32f-44b9-81ac-e26e950a902e?wsid=/subscriptions/d9412b06-e31c-4c66-b2c5-5e77beb91bc1/resourcegroups/demo-rg/workspaces/demo-ws&tid=dd1f2c2d-fea2-4bb0-a462-dfeb75d6a2e7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_run = experiment.submit(\n",
    "    inference_pipeline, pipeline_parameters={\"hierarchy_forecast_level\": \"state\"}\n",
    ")\n",
    "inference_run.wait_for_completion(show_output=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
